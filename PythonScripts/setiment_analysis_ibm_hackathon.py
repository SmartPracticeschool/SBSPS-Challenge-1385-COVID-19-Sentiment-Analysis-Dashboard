# -*- coding: utf-8 -*-
"""setiment-analysis-ibm-hackathon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EL56Z30MHIq2xYmfEhcO7BIhQ4Ak2_vf
"""

# Commented out IPython magic to ensure Python compatibility.
import datetime as dt
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
from google.colab import drive

drive.mount('drive', force_remount=True)

import json
!pip install "ibm-watson>=4.5.0"
from ibm_watson import ToneAnalyzerV3, ApiException
from ibm_cloud_sdk_core.authenticators import IAMAuthenticator

# language processing libs
!pip install vaderSentiment
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import re
!pip install emoji
import emoji

"""##Data Preprocessing"""

def data_pre_processing(data_frame_arg):
  # data preprocessing
  # removing unwanted stuff from text of tweet using regex

  #replacing & with and
  data_frame_arg["clean_text"] = data_frame_arg["text"].to_numpy()

  #Removing URLs
  def removeURLs(str):
      return re.sub(r'https?://\S+', ' ', str)
  data_frame_arg["clean_text"] = data_frame_arg["clean_text"].apply(lambda tweet: removeURLs(tweet))

  def proc(text):
    text = emoji.demojize(text, use_aliases=True, delimiters=('','')).replace('_', ' ').replace('&', 'and').replace('.', '. ').replace(',', ', ').replace('#', '# ').replace('?', '? ').replace('!', '! ').replace('&', 'and')
    return re.sub(r'\s+', ' ', text)
  data_frame_arg["clean_text"] = data_frame_arg["clean_text"].apply(lambda tweet: proc(tweet))

"""##VADER Sentiment Analysis"""

def get_score_df(data_frame_arg):
  sia = SentimentIntensityAnalyzer()
  scores_ = data_frame_arg["text"].apply(lambda tweet: sia.polarity_scores(tweet))
  scores_df_ret = pd.DataFrame(list(scores_))
  scores_df_ret['result'] = scores_df_ret['compound'].apply(lambda res: 'neutral' if res == 0 else ('positive' if res > 0 else 'negative'))
  for col in scores_df_ret:
    data_frame_arg[col] = scores_df_ret[col].to_numpy()

"""## IBM Watson Tone Analyser"""

# IBM Watson Tone Analyser
def get_tones(data_frame_arg):
  row_list = []
  def get_single_tone(text):
    tone_analysis = tone_analyzer.tone({'text': text}, content_type='application/json', sentences=False).get_result()
    dict1 = {'analytical': 0, 'anger': 0,'confident': 0, 'fear': 0, 'joy': 0, 'sadness': 0, 'tentative': 0}
    for tone in tone_analysis['document_tone']['tones']:
      dict1.update({tone['tone_id'] : tone['score']})
    row_list.append(dict1)
  data_frame_arg['clean_text'].apply(lambda tweet: get_single_tone(tweet))
  df = pd.DataFrame(row_list)
  for col in df:
    data_frame_arg[col] = df[col].to_numpy()

df = pd.read_csv('drive/My Drive/colab_drive/ibm_hackathon_2020/final_lockdown_tweets/MarchFinal.csv')
df.head()

df2 = df[2500:].copy()
data_pre_processing(df2)
get_score_df(df2)

apikey = '**********'
authenticator = IAMAuthenticator(apikey)
tone_analyzer = ToneAnalyzerV3(
    version='2017-09-21',
    authenticator=authenticator
)
url = '*******************'
tone_analyzer.set_service_url(url)
get_tones(df2)
df2.to_csv('drive/My Drive/colab_drive/ibm_hackathon_2020/final_temp_tweets/df_march2.csv', index=False)
df2.head()

df_march_fin = df1.copy()

df_march_fin = df_march_fin.append(df2, ignore_index=True)
df_march_fin.head()

df_march_fin.to_csv('drive/My Drive/colab_drive/ibm_hackathon_2020/final_lockdown_tweets/MarchFinalWithSentiments.csv', index=False)